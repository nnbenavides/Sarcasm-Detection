{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Nicholas Benavides, Ray Thai, & Crystal Zheng\n",
    "# Code liberally inspired by and lifted from:\n",
    "# https://github.com/kolchinski/reddit-sarc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "from itertools import islice, chain\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_dir = '../SARC/2.0/pol'\n",
    "comments_file = os.path.join(pol_dir, 'comments.json')\n",
    "train_file = os.path.join(pol_dir, 'train-balanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(comments_file, 'r') as f:\n",
    "    comments = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('7uxqr', {'text': 'Nancyt Pelosi messes up.. 500 Million Jobs lost every month that the economic recovery plan is not passed.. LMAO', 'author': 'Fishbum', 'score': 0, 'ups': 2, 'downs': 4, 'date': '2009-02', 'created_utc': 1233788424, 'subreddit': 'politics'}) \n",
      "\n",
      "('7vewt', {'text': 'Netflix CEO: \"Please raise my taxes\"', 'author': 'jdl2003', 'score': 1733, 'ups': 1985, 'downs': 252, 'date': '2009-02', 'created_utc': 1233940024, 'subreddit': 'politics'}) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in islice(comments.items(), 2):\n",
    "    print(x, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ancestors = []\n",
    "train_responses = []\n",
    "train_labels = []\n",
    "lower = True\n",
    "with open(train_file, 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='|')\n",
    "    for row in reader:\n",
    "        ancestors = row[0].split(' ')\n",
    "        responses = row[1].split(' ')\n",
    "        labels = row[2].split(' ')\n",
    "        if lower:\n",
    "            train_ancestors.append([comments[r]['text'].lower() for r in ancestors])\n",
    "            train_responses.append([comments[r]['text'].lower() for r in responses])\n",
    "        else:\n",
    "            train_ancestors.append([comments[r]['text'] for r in ancestors])\n",
    "            train_responses.append([comments[r]['text'] for r in responses])\n",
    "        train_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (1, 2), (2, 2)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(len(x), len(y)) for x,y in zip(train_ancestors, train_responses)][:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['new jersey governor chris christie thinks a family making $6,000 a year is too rich to qualify for medicaid',\n",
       "  \"if you have a kid and the best you can do is a minimum wage job then i think you've made some bad choices in the past\"],\n",
       " [\"yah, at that point they don't even count as people anymore!\",\n",
       "  'do you by any chance know what the term \"structural unemployment\" means?'],\n",
       " ['1', '0'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ancestors[8], train_responses[8], train_labels[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13630\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "train_vocab = defaultdict(int)\n",
    "for pair in train_responses:\n",
    "    for comment in pair:\n",
    "        for w in nltk.word_tokenize(comment):\n",
    "            train_vocab[w] += 1\n",
    "train_vocab = Counter(train_vocab)\n",
    "print(len(train_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 7226), ('the', 6553), (',', 5269), ('to', 4080), ('a', 3342)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vocab.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigrams_phi_c(comment):\n",
    "    return Counter(nltk.word_tokenize(comment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_phi_r(response_features_pair):\n",
    "    assert len(response_features_pair) == 2\n",
    "    #print(response_features_pair[0].shape, response_features_pair[1].shape)\n",
    "    cat = np.concatenate((response_features_pair[0], response_features_pair[1]))\n",
    "    return cat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phi_c turns comments into features\n",
    "#phi_a combines ancestor features into summary\n",
    "#phi_r combines response features into summary\n",
    "#Note that this is for the \"balanced\" framing!\n",
    "#TODO: Initially ignoring ancestors, include them as another vector later\n",
    "def build_dataset(ancestors, responses, labels, phi_c, phi_a, phi_r, vectorizer=None, vectorize = True):\n",
    "    X = []\n",
    "    Y = []\n",
    "    feat_dicts = [[],[]]\n",
    "    N = len(ancestors)\n",
    "    assert N == len(responses) == len(labels)\n",
    "    print(N)\n",
    "    for i in range(N):\n",
    "        assert len(responses[i]) == 2\n",
    "        feat_dicts[0].append(phi_c(responses[i][0]))\n",
    "        feat_dicts[1].append(phi_c(responses[i][1]))\n",
    "    \n",
    "        #We only care about the first of the two labels since in the balanced setting\n",
    "        #they're either 0 1 or 1 0\n",
    "        Y.append(int(labels[i][0]))\n",
    "            \n",
    "    if vectorize:\n",
    "        # In training, we want a new vectorizer:\n",
    "        if vectorizer == None:\n",
    "            vectorizer = DictVectorizer(sparse=False)\n",
    "            #print(feat_dicts[0][:10], feat_dicts[1][:10])\n",
    "            feat_matrix = vectorizer.fit_transform(feat_dicts[0] + feat_dicts[1])\n",
    "        # In assessment, we featurize using the existing vectorizer:\n",
    "        else:\n",
    "            feat_matrix = vectorizer.transform(chain(feat_dicts[0], feat_dicts[1]))\n",
    "        \n",
    "        response_pair_feats = [feat_matrix[:N], feat_matrix[N:]]\n",
    "    else:\n",
    "        response_pair_feats = feat_dicts\n",
    "        #print(response_pair_feats[0])\n",
    "\n",
    "    #assert len(feat_matrix == 2*N) \n",
    "    #print((feat_matrix[0]), len(feat_matrix[1]))\n",
    "    \n",
    "    X = [phi_r((response_pair_feats[0][i], response_pair_feats[1][i])) for i in range(N)]\n",
    "    #X = list(map(phi_r, response_pair_feats))\n",
    "    \n",
    "    return {'X': np.array(X),\n",
    "            'y': np.array(Y),\n",
    "            'vectorizer': vectorizer,\n",
    "            'raw_examples': (ancestors, responses)}\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = train_responses\n",
    "phi_c = unigrams_phi_c\n",
    "N = len(responses)\n",
    "feat_dicts = [[],[]]\n",
    "for i in range(N):\n",
    "    assert len(responses[i]) == 2\n",
    "    feat_dicts[0].append(phi_c(responses[i][0]))\n",
    "    feat_dicts[1].append(phi_c(responses[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6834, 27260)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_dataset = build_dataset(train_ancestors, train_responses, train_labels, unigrams_phi_c, None, concat_phi_r)\n",
    "\n",
    "unigram_dataset['X'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_maxent_classifier(X, y):  \n",
    "    #print(X.shape, y.shape)\n",
    "    mod = LogisticRegression(fit_intercept=True)\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_naive_bayes_classifier(X, y):  \n",
    "    #print(X.shape, y.shape)\n",
    "    mod = MultinomialNB()\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xval_model(model_fit_fn, X, y, folds):\n",
    "    kf = KFold(folds)\n",
    "    for train, test in kf.split(X, y):\n",
    "        model = model_fit_fn(X[train], y[train])\n",
    "        predictions = model.predict(X[test])\n",
    "        print(classification_report(y[test], predictions, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.736     0.727     0.731       352\n",
      "           1      0.714     0.723     0.719       332\n",
      "\n",
      "   micro avg      0.725     0.725     0.725       684\n",
      "   macro avg      0.725     0.725     0.725       684\n",
      "weighted avg      0.725     0.725     0.725       684\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.698     0.729     0.713       329\n",
      "           1      0.738     0.707     0.722       355\n",
      "\n",
      "   micro avg      0.718     0.718     0.718       684\n",
      "   macro avg      0.718     0.718     0.718       684\n",
      "weighted avg      0.719     0.718     0.718       684\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.748     0.757     0.752       345\n",
      "           1      0.749     0.740     0.745       339\n",
      "\n",
      "   micro avg      0.749     0.749     0.749       684\n",
      "   macro avg      0.749     0.748     0.748       684\n",
      "weighted avg      0.749     0.749     0.749       684\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.747     0.745     0.746       365\n",
      "           1      0.709     0.712     0.710       319\n",
      "\n",
      "   micro avg      0.730     0.730     0.730       684\n",
      "   macro avg      0.728     0.728     0.728       684\n",
      "weighted avg      0.730     0.730     0.730       684\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.728     0.723     0.725       347\n",
      "           1      0.716     0.720     0.718       336\n",
      "\n",
      "   micro avg      0.722     0.722     0.722       683\n",
      "   macro avg      0.722     0.722     0.722       683\n",
      "weighted avg      0.722     0.722     0.722       683\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.698     0.698     0.698       331\n",
      "           1      0.716     0.716     0.716       352\n",
      "\n",
      "   micro avg      0.707     0.707     0.707       683\n",
      "   macro avg      0.707     0.707     0.707       683\n",
      "weighted avg      0.707     0.707     0.707       683\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.735     0.801     0.767       347\n",
      "           1      0.774     0.702     0.736       336\n",
      "\n",
      "   micro avg      0.753     0.753     0.753       683\n",
      "   macro avg      0.755     0.752     0.752       683\n",
      "weighted avg      0.754     0.753     0.752       683\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.704     0.687     0.695       332\n",
      "           1      0.710     0.726     0.718       351\n",
      "\n",
      "   micro avg      0.707     0.707     0.707       683\n",
      "   macro avg      0.707     0.707     0.707       683\n",
      "weighted avg      0.707     0.707     0.707       683\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.759     0.701     0.729       345\n",
      "           1      0.717     0.772     0.744       338\n",
      "\n",
      "   micro avg      0.736     0.736     0.736       683\n",
      "   macro avg      0.738     0.737     0.736       683\n",
      "weighted avg      0.738     0.736     0.736       683\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.704     0.751     0.727       345\n",
      "           1      0.727     0.678     0.701       338\n",
      "\n",
      "   micro avg      0.714     0.714     0.714       683\n",
      "   macro avg      0.715     0.714     0.714       683\n",
      "weighted avg      0.715     0.714     0.714       683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xval_model(fit_maxent_classifier, unigram_dataset['X'], unigram_dataset['y'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.727     0.732     0.730      1147\n",
      "           1      0.727     0.721     0.724      1131\n",
      "\n",
      "   micro avg      0.727     0.727     0.727      2278\n",
      "   macro avg      0.727     0.727     0.727      2278\n",
      "weighted avg      0.727     0.727     0.727      2278\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.696     0.716     0.706      1156\n",
      "           1      0.699     0.677     0.688      1122\n",
      "\n",
      "   micro avg      0.697     0.697     0.697      2278\n",
      "   macro avg      0.697     0.697     0.697      2278\n",
      "weighted avg      0.697     0.697     0.697      2278\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.710     0.720     0.715      1135\n",
      "           1      0.718     0.709     0.713      1143\n",
      "\n",
      "   micro avg      0.714     0.714     0.714      2278\n",
      "   macro avg      0.714     0.714     0.714      2278\n",
      "weighted avg      0.714     0.714     0.714      2278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xval_model(fit_naive_bayes_classifier, unigram_dataset['X'], unigram_dataset['y'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "11990\n",
      "<class 'numpy.ndarray'> (300,) 0.03160001061769435\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "fasttext_lookup = {}\n",
    "with open('../../static/wiki-news-300d-1M-subword.vec') as f:\n",
    "    while True:\n",
    "        try:\n",
    "            x = next(f)\n",
    "        except:\n",
    "            break\n",
    "        try:\n",
    "            fields = x.strip().split()\n",
    "            idx = fields[0]\n",
    "            if idx not in train_vocab: continue\n",
    "            if idx in fasttext_lookup:\n",
    "                print(\"Duplicate! \", idx)\n",
    "            vec = np.array(fields[1:], dtype=np.float32)\n",
    "            fasttext_lookup[idx] = vec\n",
    "            i += 1\n",
    "            if i%500 == 0: print(i)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "print(len(fasttext_lookup))\n",
    "print(type(fasttext_lookup['the']), fasttext_lookup['the'].shape, sum(fasttext_lookup['the']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_phi_c(comment, embeddings):\n",
    "    words = nltk.word_tokenize(comment)\n",
    "    unk = np.zeros(next(iter(embeddings.values())).shape)\n",
    "    return np.sum([embeddings[w] if w in embeddings else unk for w in words], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_phi_c(comment):\n",
    "    return embed_phi_c(comment, fasttext_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6834, 600)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_dataset = build_dataset(\n",
    "    train_ancestors, train_responses, train_labels, fasttext_phi_c, None, concat_phi_r, None, False)\n",
    "\n",
    "fasttext_dataset['X'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.703     0.709     0.706      1147\n",
      "           1      0.702     0.696     0.699      1131\n",
      "\n",
      "   micro avg      0.702     0.702     0.702      2278\n",
      "   macro avg      0.702     0.702     0.702      2278\n",
      "weighted avg      0.702     0.702     0.702      2278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.716     0.702     0.709      1156\n",
      "           1      0.699     0.713     0.706      1122\n",
      "\n",
      "   micro avg      0.707     0.707     0.707      2278\n",
      "   macro avg      0.707     0.707     0.707      2278\n",
      "weighted avg      0.707     0.707     0.707      2278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.698     0.707     0.702      1135\n",
      "           1      0.705     0.696     0.701      1143\n",
      "\n",
      "   micro avg      0.701     0.701     0.701      2278\n",
      "   macro avg      0.702     0.702     0.701      2278\n",
      "weighted avg      0.702     0.701     0.701      2278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xval_model(fit_maxent_classifier, fasttext_dataset['X'], fasttext_dataset['y'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove.6B.100d.txt  glove.6B.200d.txt  glove.6B.300d.txt  glove.6B.50d.txt\r\n"
     ]
    }
   ],
   "source": [
    "%ls ../../static/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "11824\n",
      "<class 'numpy.ndarray'> (300,) 3.823568901862018\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "glove_lookup = {}\n",
    "with open('../../static/glove/glove.6B.300d.txt') as f:\n",
    "#with open('../../static/') as f:\n",
    "    while True:\n",
    "        try:\n",
    "            x = next(f)\n",
    "        except:\n",
    "            break\n",
    "        try:\n",
    "            fields = x.strip().split()\n",
    "            idx = fields[0]\n",
    "            if idx not in train_vocab: continue\n",
    "            if idx in glove_lookup:\n",
    "                print(\"Duplicate! \", idx)\n",
    "            vec = np.array(fields[1:], dtype=np.float32)\n",
    "            glove_lookup[idx] = vec\n",
    "            i += 1\n",
    "            if i%500 == 0: print(i)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "print(len(glove_lookup))\n",
    "print(type(glove_lookup['the']), glove_lookup['the'].shape, sum(glove_lookup['the']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6834, 600)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def glove_phi_c(comment):\n",
    "    return embed_phi_c(comment, glove_lookup)\n",
    "\n",
    "glove_dataset = build_dataset(\n",
    "    train_ancestors, train_responses, train_labels, glove_phi_c, None, concat_phi_r, None, False)\n",
    "\n",
    "fasttext_dataset['X'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.669     0.674     0.672       681\n",
      "           1      0.674     0.669     0.672       686\n",
      "\n",
      "   micro avg      0.672     0.672     0.672      1367\n",
      "   macro avg      0.672     0.672     0.672      1367\n",
      "weighted avg      0.672     0.672     0.672      1367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.688     0.684     0.686       708\n",
      "           1      0.662     0.666     0.664       659\n",
      "\n",
      "   micro avg      0.675     0.675     0.675      1367\n",
      "   macro avg      0.675     0.675     0.675      1367\n",
      "weighted avg      0.675     0.675     0.675      1367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.675     0.652     0.664       679\n",
      "           1      0.668     0.690     0.679       688\n",
      "\n",
      "   micro avg      0.672     0.672     0.672      1367\n",
      "   macro avg      0.672     0.671     0.671      1367\n",
      "weighted avg      0.672     0.672     0.671      1367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.669     0.665     0.667       680\n",
      "           1      0.670     0.674     0.672       687\n",
      "\n",
      "   micro avg      0.669     0.669     0.669      1367\n",
      "   macro avg      0.669     0.669     0.669      1367\n",
      "weighted avg      0.669     0.669     0.669      1367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.681     0.688     0.684       690\n",
      "           1      0.678     0.670     0.674       676\n",
      "\n",
      "   micro avg      0.679     0.679     0.679      1366\n",
      "   macro avg      0.679     0.679     0.679      1366\n",
      "weighted avg      0.679     0.679     0.679      1366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xval_model(fit_maxent_classifier, glove_dataset['X'], glove_dataset['y'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.commands.elmo import ElmoEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo = ElmoEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elmo_phi_c(comment):\n",
    "    vecs = elmo.embed_sentence(nltk.word_tokenize(comment))\n",
    "    elmo_avg_vec = vecs.mean(axis = 0)\n",
    "    #print(elmo_avg_vec)\n",
    "    return elmo_avg_vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6834\n"
     ]
    }
   ],
   "source": [
    "elmo_dataset = build_dataset(\n",
    "    train_ancestors, train_responses, train_labels, elmo_phi_c, None, concat_phi_r, None, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.699     0.705     0.702       352\n",
      "           1      0.684     0.678     0.681       332\n",
      "\n",
      "   micro avg      0.692     0.692     0.692       684\n",
      "   macro avg      0.691     0.691     0.691       684\n",
      "weighted avg      0.691     0.692     0.691       684\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.666     0.690     0.678       329\n",
      "           1      0.703     0.679     0.691       355\n",
      "\n",
      "   micro avg      0.684     0.684     0.684       684\n",
      "   macro avg      0.684     0.684     0.684       684\n",
      "weighted avg      0.685     0.684     0.684       684\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.649     0.643     0.646       345\n",
      "           1      0.640     0.646     0.643       339\n",
      "\n",
      "   micro avg      0.645     0.645     0.645       684\n",
      "   macro avg      0.645     0.645     0.645       684\n",
      "weighted avg      0.645     0.645     0.645       684\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.718     0.677     0.697       365\n",
      "           1      0.653     0.696     0.674       319\n",
      "\n",
      "   micro avg      0.686     0.686     0.686       684\n",
      "   macro avg      0.685     0.686     0.685       684\n",
      "weighted avg      0.688     0.686     0.686       684\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.671     0.651     0.661       347\n",
      "           1      0.650     0.670     0.660       336\n",
      "\n",
      "   micro avg      0.660     0.660     0.660       683\n",
      "   macro avg      0.660     0.660     0.660       683\n",
      "weighted avg      0.661     0.660     0.660       683\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.612     0.604     0.608       331\n",
      "           1      0.632     0.639     0.636       352\n",
      "\n",
      "   micro avg      0.622     0.622     0.622       683\n",
      "   macro avg      0.622     0.622     0.622       683\n",
      "weighted avg      0.622     0.622     0.622       683\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.683     0.709     0.696       347\n",
      "           1      0.687     0.661     0.674       336\n",
      "\n",
      "   micro avg      0.685     0.685     0.685       683\n",
      "   macro avg      0.685     0.685     0.685       683\n",
      "weighted avg      0.685     0.685     0.685       683\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.646     0.693     0.669       332\n",
      "           1      0.688     0.641     0.664       351\n",
      "\n",
      "   micro avg      0.666     0.666     0.666       683\n",
      "   macro avg      0.667     0.667     0.666       683\n",
      "weighted avg      0.668     0.666     0.666       683\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.705     0.672     0.688       345\n",
      "           1      0.681     0.713     0.697       338\n",
      "\n",
      "   micro avg      0.693     0.693     0.693       683\n",
      "   macro avg      0.693     0.693     0.692       683\n",
      "weighted avg      0.693     0.693     0.692       683\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/nlu/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.657     0.667     0.662       345\n",
      "           1      0.655     0.645     0.650       338\n",
      "\n",
      "   micro avg      0.656     0.656     0.656       683\n",
      "   macro avg      0.656     0.656     0.656       683\n",
      "weighted avg      0.656     0.656     0.656       683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xval_model(fit_maxent_classifier, elmo_dataset['X'], elmo_dataset['y'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu",
   "language": "python",
   "name": "nlu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
